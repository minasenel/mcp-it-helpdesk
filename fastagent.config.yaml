# FastAgent Configuration File

# Default Model Configuration:
# 
# Takes format:
#   <provider>.<model_string>.<reasoning_effort?> (e.g. anthropic.claude-3-5-sonnet-20241022 or openai.o3-mini.low)
# Accepts aliases for Anthropic Models: haiku, haiku3, sonnet, sonnet35, opus, opus3
# and OpenAI Models: gpt-4.1, gpt-4.1-mini, o1, o1-mini, o3-mini
#
# If not specified, defaults to "haiku". 
# Can be overriden with a command line switch --model=<model>, or within the Agent constructor.

default_model: "google.gemini-1.5-flash"

# Logging and Console Configuration:
logger:
    # level: "debug" | "info" | "warning" | "error"
    level: "debug"
    # type: "none" | "console" | "file" | "http"
    type: "file"
    path: "/Users/minasenel/Desktop/mcp_test/fastagent.jsonl"
    
    # Switch the progress display on or off
    progress_display: true

    # Show chat User/Assistant messages on the console
    show_chat: true
    # Show tool calls on the console
    show_tools: true
    # Truncate long tool responses on the console 
    truncate_tools: false

# MCP Servers
mcp:
    servers:
        it-help-desk:
            command: "/Users/minasenel/Desktop/mcp_test/.venv/bin/python"
            args: ["-u", "main.py"]
            working_directory: "/Users/minasenel/Desktop/mcp_test"
            environment:
                PYTHONPATH: "/Users/minasenel/Desktop/mcp_test/.venv/lib/python3.13/site-packages"
                PYTHONUNBUFFERED: "1"

agents:
  - name: agent
    model: "google.gemini-2.0-flash"
    # Attach these MCP servers to the agent so their tools are available
    mcp_servers:
      - it-help-desk